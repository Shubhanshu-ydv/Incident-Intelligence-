# Pathway RAG Configuration for Incident Intelligence
# Uses Mistral via Ollama for fully private, local RAG
# Simplified config for Pathway v0.28.0

# ============================================================
# DATA SOURCE - Local files (populated by Supabase poller)
# ============================================================
$sources:
  - !pw.io.fs.read
    path: /home/shubh/pathway-cache
    format: binary
    mode: streaming  # Enable auto-detection of new files
    with_metadata: true

# ============================================================
# LLM CONFIGURATION (Groq - Llama 3.3 70B - Best Quality)
# ============================================================
$llm: !pw.xpacks.llm.llms.LiteLLMChat
  model: "groq/llama-3.3-70b-versatile"
  retry_strategy: !pw.udfs.ExponentialBackoffRetryStrategy
    max_retries: 6
  cache_strategy: !pw.udfs.DefaultCache {}
  temperature: 0

# ============================================================
# EMBEDDER CONFIGURATION
# ============================================================
$embedder: !pw.xpacks.llm.embedders.SentenceTransformerEmbedder
  model: "all-MiniLM-L6-v2"

# ============================================================
# TEXT SPLITTER (Phase 2: Smaller chunks for better focus)
# ============================================================
$splitter: !pw.xpacks.llm.splitters.TokenCountSplitter
  max_tokens: 200  # Reduced from 400 for more focused semantic chunks

# ============================================================
# VECTOR INDEX
# ============================================================
$retriever_factory: !pw.indexing.UsearchKnnFactory
  reserved_space: 1000
  embedder: $embedder
  metric: !pw.indexing.USearchMetricKind.COS

# ============================================================
# DOCUMENT STORE (Phase 2: Increased retrieval for better recall)
# ============================================================
$document_store: !pw.xpacks.llm.document_store.DocumentStore
  docs: $sources
  splitter: $splitter
  retriever_factory: $retriever_factory

# ============================================================
# QUESTION ANSWERER (Base - compatible with v0.28.0)
# Phase 2: Using overlap_tokens for better context preservation
# ============================================================
question_answerer: !pw.xpacks.llm.question_answering.BaseRAGQuestionAnswerer
  llm: $llm
  indexer: $document_store

# ============================================================
# SERVER CONFIGURATION
# ============================================================
host: "0.0.0.0"
port: 8081
